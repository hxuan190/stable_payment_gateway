# MVP v1.1 Plan Review & Critique

**Review Date**: 2025-11-18
**Reviewer**: Critical Analysis
**Documents Reviewed**:
- `TECH_STACK_DECISIONS.md` (681 lines)
- `MVP_V1.1_TASK_BREAKDOWN.md` (1080 lines)
- `REQUIREMENTS_MVP_V1.1.md`

---

## üéØ Executive Summary

**Overall Assessment**: ‚≠ê‚≠ê‚≠ê‚≠ê (4/5) - **Good plan with several critical gaps**

**Strengths**:
- ‚úÖ Comprehensive task breakdown with clear DoD
- ‚úÖ Realistic 3-week timeline
- ‚úÖ Good separation of concerns (Epic 1 vs Epic 2)
- ‚úÖ Identifies existing vs missing components

**Critical Gaps**:
- ‚ùå No data migration strategy for existing merchants
- ‚ùå Missing integration testing plan
- ‚ùå No rollback procedures for critical migrations
- ‚ùå WebSocket scaling not addressed
- ‚ùå No performance benchmarks defined
- ‚ö†Ô∏è TRM Labs cost not validated ($500/mo assumption may be wrong)

**Recommendation**: **Approve with modifications** - Address critical gaps before starting implementation

---

## üìã Detailed Review by Section

### 1. EPIC 1: Compliance Engine

#### ‚úÖ Strengths

**Good Task Granularity**:
- Clear separation: models ‚Üí migrations ‚Üí services ‚Üí APIs
- Each task has specific file paths
- Code examples provided

**Realistic Complexity Assessment**:
- Correctly identifies audit logs partitioning as CRITICAL
- Recognizes refactoring needs in existing code

#### ‚ùå Critical Issues

**Issue 1.1: Missing Data Migration for Existing Merchants**
```
Problem: Plan assumes fresh start, but you have existing data
Impact: If merchants table has data, migration 011 will:
  - Set all merchants to tier1 (correct)
  - Set monthly_limit_usd to $5000 (may be too low for some)
  - Reset volume counters (may be incorrect)

Missing:
  - [ ] Pre-migration data audit
  - [ ] Merchant tier assignment logic
  - [ ] Volume backfill from payments table
```

**Recommendation**:
Add **Task 1.0.1: Pre-Migration Data Audit**
```sql
-- Before migration 011
SELECT
    id,
    business_name,
    SUM(amount_vnd) / 23000 as total_volume_usd
FROM merchants m
JOIN payments p ON p.merchant_id = m.id
WHERE p.status = 'completed'
  AND p.created_at > date_trunc('month', NOW())
GROUP BY m.id
HAVING SUM(amount_vnd) / 23000 > 5000;

-- These merchants need tier2 or tier3 before applying limits
```

---

**Issue 1.2: Audit Logs Partitioning - No Rollback Plan**
```
Problem: Task 1.1.5 migration is DANGEROUS
Risk: If partition creation fails mid-migration:
  - audit_logs_old contains data
  - audit_logs (partitioned) partially populated
  - System broken, no way to recover

Missing:
  - [ ] Rollback procedure
  - [ ] Data verification steps
  - [ ] Downtime estimation
  - [ ] Backup requirement
```

**Recommendation**:
Update **Task 1.1.5** with safe migration procedure:
```sql
-- STEP 0: BACKUP (not in migration file, manual step)
-- pg_dump -t audit_logs > audit_logs_backup.sql

-- STEP 1: Create partitioned table with temp name
CREATE TABLE audit_logs_partitioned (
    -- same schema
) PARTITION BY RANGE (created_at);

-- STEP 2: Create partitions
CREATE TABLE audit_logs_2025 PARTITION OF audit_logs_partitioned ...;

-- STEP 3: Copy data (THIS CAN FAIL - need to handle)
INSERT INTO audit_logs_partitioned
SELECT * FROM audit_logs;
-- Verify count matches
DO $$
DECLARE
    old_count BIGINT;
    new_count BIGINT;
BEGIN
    SELECT COUNT(*) INTO old_count FROM audit_logs;
    SELECT COUNT(*) INTO new_count FROM audit_logs_partitioned;
    IF old_count != new_count THEN
        RAISE EXCEPTION 'Data verification failed: % != %', old_count, new_count;
    END IF;
END $$;

-- STEP 4: Atomic swap (use transaction)
BEGIN;
    ALTER TABLE audit_logs RENAME TO audit_logs_old;
    ALTER TABLE audit_logs_partitioned RENAME TO audit_logs;
    -- Recreate indexes
    -- If this fails, rollback restores old table
COMMIT;

-- STEP 5: Keep audit_logs_old for 1 week, then drop
```

Add **Rollback Plan**:
```sql
-- If migration fails AFTER atomic swap
BEGIN;
    DROP TABLE IF EXISTS audit_logs;
    ALTER TABLE audit_logs_old RENAME TO audit_logs;
COMMIT;
```

---

**Issue 1.3: TRM Labs Integration - No Fallback**
```
Problem: Plan assumes TRM Labs API always available
What if:
  - TRM Labs is down during payment creation?
  - Rate limit exceeded?
  - API key invalid?
  - Cost > $500/mo (actual pricing not verified)?

Missing:
  - [ ] Fallback strategy (allow payment or reject?)
  - [ ] Circuit breaker pattern
  - [ ] Cost validation (get actual quote)
  - [ ] SLA requirements for compliance
```

**Recommendation**:
Add **Task 1.2.1b: AML Fallback Strategy**
```go
type AMLService struct {
    trmClient    *trmlabs.Client
    circuitBreaker *CircuitBreaker
    fallbackMode   string // "allow", "reject", "manual_review"
}

func (s *AMLService) ScreenWalletAddress(ctx context.Context, address string) (*AMLResult, error) {
    // Try TRM Labs
    if s.circuitBreaker.IsOpen() {
        return s.handleFallback(address)
    }

    result, err := s.trmClient.ScreenAddress(ctx, address)
    if err != nil {
        s.circuitBreaker.RecordFailure()
        return s.handleFallback(address)
    }

    return result, nil
}

func (s *AMLService) handleFallback(address string) (*AMLResult, error) {
    switch s.fallbackMode {
    case "allow":
        // Log warning, allow payment, flag for manual review
        return &AMLResult{IsSafe: true, RequiresManualReview: true}, nil
    case "reject":
        return nil, ErrAMLServiceUnavailable
    case "manual_review":
        // Create manual review task
        return &AMLResult{IsSafe: false, RequiresManualReview: true}, nil
    }
}
```

**Cost Validation**:
- ‚ö†Ô∏è Task breakdown assumes $500/mo for TRM Labs
- **Action Required**: Get actual quote before implementation
- TRM Labs pricing tiers (unverified):
  - Starter: ~$1000/mo for 1K screenings
  - Growth: ~$3000/mo for 10K screenings
- **Alternative**: Consider cheaper options first:
  - Chainalysis KYT: ~$1500/mo
  - Elliptic: ~$800/mo
  - Build simple OFAC list checker (free): $0/mo

---

**Issue 1.4: S3/Glacier Lifecycle - Missing Testing Plan**
```
Problem: S3 Glacier lifecycle is NOT instant
Reality:
  - Transition to Glacier: Takes 24-48 hours
  - Restore from Glacier: Takes 3-5 hours (Standard retrieval)

Missing:
  - [ ] How to test Glacier retrieval in dev/staging?
  - [ ] What if regulator needs KYC doc immediately?
  - [ ] Cost implications (retrieval fees)
```

**Recommendation**:
Update **Task 1.2.3** with hybrid storage strategy:
```go
// Keep critical KYC docs in S3 Standard for active merchants
// Only archive after merchant closed + 90 days

type StorageService interface {
    UploadKYCDocument(ctx context.Context, doc *KYCDocument) (string, error)

    // For active merchant: S3 Standard
    // For closed merchant (< 90d): S3 Standard-IA
    // For closed merchant (> 90d): S3 Glacier
    GetStorageClass(merchantStatus string, closedDate time.Time) string
}

// Lifecycle policy
if merchant.Status == "closed" &&
   time.Since(merchant.ClosedAt) > 90*24*time.Hour {
    // Transition to Glacier
} else {
    // Keep in Standard
}
```

---

### 2. EPIC 2: Payer Experience Layer

#### ‚úÖ Strengths

**Clear Separation**:
- Backend (WebSocket) separate from Frontend (Next.js)
- Good identification of Redis Pub/Sub needs

**Realistic Scope**:
- Payment status page + success page = MVP complete
- No over-engineering

#### ‚ùå Critical Issues

**Issue 2.1: WebSocket Scaling Not Addressed**
```
Problem: Plan assumes single server
Reality: What happens with multiple API servers?

Scenario:
  Server A: Handles payment creation
  Server B: User connects WebSocket
  ‚Üí Redis Pub/Sub required for cross-server communication
  ‚Üí Plan mentions this but NO implementation details

Missing:
  - [ ] How does blockchain listener publish to Redis?
  - [ ] How do multiple servers coordinate?
  - [ ] Load balancer sticky sessions needed?
```

**Recommendation**:
Add **Task 2.1.4: Multi-Server WebSocket Architecture**
```
Architecture:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Load Balancer   ‚îÇ
‚îÇ (sticky session)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ API-1 ‚îÇ ‚îÇ API-2 ‚îÇ
‚îÇ (WS)  ‚îÇ ‚îÇ (WS)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Redis  ‚îÇ
    ‚îÇ Pub/Sub ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Implementation:
1. Load balancer: NGINX with ip_hash (sticky sessions)
2. Each API server subscribes to Redis channel
3. Blockchain listener publishes to Redis
4. All API servers receive event, forward to connected clients
```

**NGINX Config (Missing from plan)**:
```nginx
upstream api_servers {
    ip_hash; # Sticky sessions for WebSocket
    server api-1:8080;
    server api-2:8080;
}

location /ws/ {
    proxy_pass http://api_servers;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "upgrade";

    # WebSocket timeout (30 min = payment expiry)
    proxy_read_timeout 1800s;
    proxy_send_timeout 1800s;
}
```

---

**Issue 2.2: No Frontend Error Handling Strategy**
```
Problem: Plan shows happy path only
Missing:
  - [ ] What if WebSocket disconnects?
  - [ ] What if payment expired while user offline?
  - [ ] What if blockchain confirmation takes > 30 min?
  - [ ] What if QR code fails to generate?
```

**Recommendation**:
Add **Task 2.2.5: Frontend Error Handling**
```tsx
// Scenario 1: WebSocket disconnect
useEffect(() => {
    const ws = createWebSocketConnection(paymentId)

    ws.onClose = () => {
        // Fallback to polling
        const pollInterval = setInterval(() => {
            fetchPaymentStatus(paymentId).then(setPayment)
        }, 5000)

        // Try to reconnect
        setTimeout(() => reconnect(), 3000)
    }
}, [])

// Scenario 2: Payment expired
if (payment.status === 'expired') {
    return (
        <ExpiredPage>
            <h1>Payment Expired</h1>
            <p>Please create a new payment</p>
            <Button onClick={() => window.close()}>Close</Button>
        </ExpiredPage>
    )
}

// Scenario 3: QR code failed
if (!qrCode) {
    return (
        <ManualPaymentInstructions>
            <CopyField label="Address" value={payment.walletAddress} />
            <CopyField label="Amount" value={payment.amountCrypto} />
            <CopyField label="Memo" value={payment.paymentReference} />
        </ManualPaymentInstructions>
    )
}
```

---

**Issue 2.3: No Performance Benchmarks**
```
Problem: "Payment status page load time < 2s" - but how to verify?
Missing:
  - [ ] Lighthouse CI integration
  - [ ] Load testing plan (100 concurrent WebSocket?)
  - [ ] CDN strategy for static assets
```

**Recommendation**:
Add **Task 2.4: Performance Testing**
```yaml
# .github/workflows/performance.yml
lighthouse-ci:
  - url: /order/test-payment-id
  - metrics:
      - first-contentful-paint: < 1.5s
      - time-to-interactive: < 2.5s
      - largest-contentful-paint: < 2.0s

load-testing:
  - tool: k6 or artillery
  - scenario: 100 concurrent WebSocket connections
  - acceptance:
      - < 500ms latency for status updates
      - 0% connection failures
```

---

### 3. Implementation Timeline

#### ‚úÖ Strengths

**Realistic 3-Week Estimate**:
- Week 1: Database + Services
- Week 2: Real-time infra
- Week 3: Frontend

**Good Task Dependencies**:
- Frontend depends on backend APIs ‚úÖ
- APIs depend on services ‚úÖ

#### ‚ùå Critical Issues

**Issue 3.1: No Buffer Time**
```
Problem: Timeline assumes everything goes perfectly
Reality:
  - Migrations may fail
  - TRM Labs integration may take longer (API key approval)
  - Frontend bugs always happen

Missing:
  - [ ] Buffer for integration issues
  - [ ] Time for code review
  - [ ] Time for testing
```

**Recommendation**:
Add **Week 4: Integration Testing & Bug Fixes**
```
Week 1: Database + Compliance Backend (5 days)
Week 2: Real-time Infrastructure (5 days)
Week 3: Frontend (5 days)
Week 4: Integration Testing & Fixes (5 days) ‚Üê NEW
  - Day 1-2: End-to-end testing
  - Day 3: Bug fixes
  - Day 4: Performance optimization
  - Day 5: Deploy to staging
```

**Revised Timeline**: **4 weeks** (not 3)

---

**Issue 3.2: Parallel Tasks Not Identified**
```
Problem: Plan is sequential, but some tasks can be parallel
Opportunity: If you have 2-3 developers, parallelize:

Week 1 (Parallel):
  Developer A: Database migrations (Tasks 1.1.1 - 1.1.5)
  Developer B: S3 service (Task 1.2.3)
  Developer C: TRM Labs client (Task 1.2.1)

Week 2 (Parallel):
  Developer A: WebSocket handler (Task 2.1.2)
  Developer B: Frontend setup (Task 2.2.1)
  Developer C: Compliance APIs (Task 1.3.x)
```

**Recommendation**:
Add **Task Assignment Matrix**:
```
| Week | Dev A (Backend)        | Dev B (Frontend)    | Dev C (DevOps)     |
|------|------------------------|---------------------|--------------------|
| 1    | Migrations + Services  | (idle or testing)   | S3 setup           |
| 2    | WebSocket + APIs       | Next.js setup       | Redis config       |
| 3    | Integration help       | Payment page + WS   | NGINX config       |
| 4    | Bug fixes              | Bug fixes           | Staging deployment |
```

---

### 4. Testing Strategy

#### ‚úÖ Strengths

**Good Test Categories**:
- Unit tests
- Integration tests
- End-to-end tests

#### ‚ùå Critical Issues

**Issue 4.1: No Integration Test Examples**
```
Problem: "Integration tests" mentioned but not defined
Missing:
  - [ ] How to test Travel Rule flow?
  - [ ] How to test WebSocket events?
  - [ ] How to test S3 uploads?
```

**Recommendation**:
Add **Task T.1: Integration Test Suite**
```go
// Test: Travel Rule flow
func TestPaymentCreation_WithTravelRule(t *testing.T) {
    // Given: Merchant with tier1 ($5000 limit)
    merchant := createTestMerchant(t, "tier1")

    // When: Create payment > $1000
    req := CreatePaymentRequest{
        AmountVND: decimal.NewFromInt(25_000_000), // ~$1087
        TravelRule: &TravelRuleRequest{
            PayerFullName: "John Doe",
            PayerWalletAddress: "0x1234...",
            PayerCountry: "US",
        },
    }

    // Then: Payment created + Travel Rule stored
    payment, err := paymentService.CreatePayment(ctx, req)
    assert.NoError(t, err)

    travelRule, err := travelRuleRepo.GetByPaymentID(payment.ID)
    assert.NoError(t, err)
    assert.Equal(t, "John Doe", travelRule.PayerFullName)
}

// Test: Travel Rule missing (should fail)
func TestPaymentCreation_MissingTravelRule(t *testing.T) {
    req := CreatePaymentRequest{
        AmountVND: decimal.NewFromInt(25_000_000),
        TravelRule: nil, // Missing!
    }

    _, err := paymentService.CreatePayment(ctx, req)
    assert.Error(t, err)
    assert.Contains(t, err.Error(), "TRAVEL_RULE_REQUIRED")
}
```

---

**Issue 4.2: No Load Testing Plan**
```
Problem: "100 concurrent WebSocket" mentioned but not planned
Missing:
  - [ ] Load testing tool choice
  - [ ] Load testing scenarios
  - [ ] Performance acceptance criteria
```

**Recommendation**:
Add **Task T.2: Load Testing with k6**
```javascript
// load-test.js
import ws from 'k6/ws';

export let options = {
    vus: 100, // 100 concurrent users
    duration: '5m',
};

export default function () {
    const paymentId = 'test-payment-123';
    const url = `ws://localhost:8080/ws/payments/${paymentId}`;

    ws.connect(url, {}, function (socket) {
        socket.on('open', () => {
            console.log('WebSocket connected');
        });

        socket.on('message', (data) => {
            console.log('Received:', data);
            check(data, {
                'status update received': (d) => d.includes('status'),
            });
        });

        socket.setTimeout(() => {
            socket.close();
        }, 30000); // 30s
    });
}
```

---

### 5. Deployment & Operations

#### ‚úÖ Strengths

**Docker Compose mentioned**:
- Good for dev/staging

#### ‚ùå Critical Issues

**Issue 5.1: No Staging Environment Plan**
```
Problem: Plan jumps from dev ‚Üí production
Missing:
  - [ ] Staging environment setup
  - [ ] Staging data seeding
  - [ ] Staging testing checklist
```

**Recommendation**:
Add **Task D.1: Staging Environment**
```yaml
# docker-compose.staging.yml
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: payment_gateway_staging
    volumes:
      - ./staging-seed.sql:/docker-entrypoint-initdb.d/seed.sql

  redis:
    image: redis:7

  api:
    build: .
    environment:
      ENV: staging
      DB_HOST: postgres
      REDIS_HOST: redis
      SOLANA_RPC_URL: https://api.devnet.solana.com # DEVNET!
      TRM_LABS_API_KEY: ${TRM_LABS_SANDBOX_KEY}
```

**Staging Checklist**:
- [ ] Use Solana DEVNET (not mainnet)
- [ ] Use TRM Labs sandbox
- [ ] Use MinIO (not S3) for cost savings
- [ ] Seed test merchants with different tiers
- [ ] Seed test payments with Travel Rule data

---

**Issue 5.2: No Monitoring/Alerting Defined**
```
Problem: "Monitoring" mentioned but not implemented
Missing:
  - [ ] What metrics to track?
  - [ ] What alerts to set up?
  - [ ] Logging strategy?
```

**Recommendation**:
Add **Task D.2: Monitoring & Alerting**
```yaml
# Prometheus metrics to track
metrics:
  - payment_creation_duration_seconds (histogram)
  - websocket_connections_active (gauge)
  - aml_screening_duration_seconds (histogram)
  - aml_screening_failures_total (counter)
  - redis_pubsub_publish_errors_total (counter)
  - s3_upload_duration_seconds (histogram)
  - travel_rule_missing_total (counter)

# Alerts (Grafana/AlertManager)
alerts:
  - name: AMLServiceDown
    condition: aml_screening_failures_total > 10 in 5min
    action: Send email to ops team

  - name: WebSocketHighLatency
    condition: websocket_message_latency_p95 > 1s
    action: Send Slack alert

  - name: TravelRuleMissing
    condition: travel_rule_missing_total > 0
    action: Send email to compliance officer
```

---

### 6. Security & Compliance

#### ‚úÖ Strengths

**Good security awareness**:
- HTTPS mentioned
- API authentication
- Audit logging

#### ‚ùå Critical Issues

**Issue 6.1: No PII Handling Strategy**
```
Problem: Travel Rule data contains PII (Payer full name, country)
GDPR/Vietnam Privacy Law requirements:
  - [ ] Encryption at rest for PII fields
  - [ ] Right to erasure (how to delete Travel Rule data?)
  - [ ] Data retention policy (how long to keep after 5 years?)
```

**Recommendation**:
Add **Task S.1: PII Encryption**
```go
// Encrypt PII fields before storing
type TravelRuleData struct {
    ID                  string
    PaymentID           string
    PayerFullName       string `db:"payer_full_name_encrypted"` // Encrypted!
    PayerWalletAddress  string // Not PII, keep plain
    PayerCountry        string // Not sensitive, keep plain
    PayerIDDocument     string `db:"payer_id_document_encrypted"` // Encrypted!
    // ...
}

// Use PostgreSQL pgcrypto extension
INSERT INTO travel_rule_data (payer_full_name_encrypted)
VALUES (pgp_sym_encrypt('John Doe', :encryption_key));

SELECT pgp_sym_decrypt(payer_full_name_encrypted, :encryption_key)
FROM travel_rule_data;
```

**GDPR Right to Erasure**:
```
Problem: Can't delete Travel Rule data (5-year retention)
Solution: Anonymization instead of deletion

UPDATE travel_rule_data
SET
    payer_full_name_encrypted = pgp_sym_encrypt('REDACTED', :key),
    payer_id_document_encrypted = NULL
WHERE payment_id = :payment_id;

-- Keep payment_id, country, amount for compliance
-- Remove personal identifiers
```

---

**Issue 6.2: No Rate Limiting on Public Endpoints**
```
Problem: /api/v1/public/payments/:id/status has no auth
Risk: DDoS attack, data scraping

Missing:
  - [ ] Rate limit by IP
  - [ ] CAPTCHA for excessive requests?
```

**Recommendation**:
Add **Task S.2: Public API Rate Limiting**
```go
// Rate limit: 10 requests/min per IP for public endpoints
func (m *RateLimitMiddleware) PublicRateLimit() gin.HandlerFunc {
    limiter := rate.NewLimiter(rate.Every(6*time.Second), 10) // 10/min

    return func(c *gin.Context) {
        ip := c.ClientIP()

        key := "ratelimit:public:" + ip
        if !m.redis.Allow(ctx, key, limiter) {
            c.JSON(429, dto.ErrorResponse("RATE_LIMIT_EXCEEDED",
                "Too many requests. Please try again later."))
            c.Abort()
            return
        }

        c.Next()
    }
}
```

---

## üìä Risk Assessment

### High-Risk Items (Need Mitigation)

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| **Audit logs migration fails** | Medium | CRITICAL | Add rollback plan (Issue 1.2) |
| **TRM Labs cost > budget** | High | High | Get quote first, have fallback (Issue 1.3) |
| **WebSocket doesn't scale** | Medium | High | Plan multi-server architecture (Issue 2.1) |
| **Existing merchant data lost** | Low | CRITICAL | Add pre-migration audit (Issue 1.1) |
| **S3 Glacier retrieval slow** | High | Medium | Keep active docs in Standard (Issue 1.4) |
| **Timeline overrun** | High | Medium | Add Week 4 buffer (Issue 3.1) |

### Medium-Risk Items (Monitor)

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| **Frontend bugs** | High | Medium | Add error handling (Issue 2.2) |
| **Integration issues** | Medium | Medium | Add Week 4 for testing (Issue 3.1) |
| **Performance below target** | Medium | Medium | Add load testing (Issue 4.2) |

---

## ‚úÖ Revised Plan Recommendations

### Must-Have Changes (Before Starting)

1. **Add Week 4: Integration & Testing** (Issue 3.1)
   - Timeline: 3 weeks ‚Üí 4 weeks
   - Justification: No buffer for bugs/issues

2. **Add Pre-Migration Data Audit** (Issue 1.1)
   - Task 1.0.1: Audit existing merchants
   - Assign KYC tiers before applying limits

3. **Add Audit Logs Rollback Plan** (Issue 1.2)
   - Document safe migration procedure
   - Test on staging first

4. **Validate TRM Labs Pricing** (Issue 1.3)
   - Get actual quote (not assumption)
   - Identify fallback provider

5. **Add Multi-Server WebSocket Plan** (Issue 2.1)
   - Document Redis Pub/Sub architecture
   - Add NGINX sticky sessions config

### Nice-to-Have Changes (Can Defer)

6. **Add Load Testing** (Issue 4.2)
   - k6 or artillery
   - 100 concurrent WebSocket test

7. **Add PII Encryption** (Issue 6.1)
   - pgcrypto for Travel Rule data
   - GDPR anonymization strategy

8. **Add Monitoring** (Issue 5.2)
   - Prometheus metrics
   - Grafana alerts

---

## üìã Revised Task List (Critical Additions)

### New Tasks to Add

**BEFORE Epic 1**:
- [ ] **Task 0.1**: Get TRM Labs pricing quote
- [ ] **Task 0.2**: Audit existing merchant data
- [ ] **Task 0.3**: Design PII encryption strategy

**Epic 1 Additions**:
- [ ] **Task 1.2.1b**: AML service fallback strategy
- [ ] **Task 1.1.5b**: Audit logs migration rollback plan
- [ ] **Task 1.2.3b**: S3 hybrid storage (Standard + Glacier)

**Epic 2 Additions**:
- [ ] **Task 2.1.4**: Multi-server WebSocket architecture
- [ ] **Task 2.2.5**: Frontend error handling
- [ ] **Task 2.3.1b**: NGINX sticky sessions config

**New Epic 3: Testing & Deployment**:
- [ ] **Task 3.1**: Integration test suite
- [ ] **Task 3.2**: Load testing with k6
- [ ] **Task 3.3**: Staging environment setup
- [ ] **Task 3.4**: Monitoring & alerting
- [ ] **Task 3.5**: PII encryption implementation

---

## üéØ Final Recommendation

**Status**: **APPROVE WITH MODIFICATIONS**

**Action Items**:
1. ‚úÖ Review this critique with team
2. ‚úÖ Validate TRM Labs pricing (1 day)
3. ‚úÖ Add Week 4 to timeline (4 weeks total)
4. ‚úÖ Add rollback plans for critical migrations
5. ‚úÖ Document multi-server WebSocket architecture
6. ‚úÖ Create staging environment setup
7. ‚úÖ Start implementation with revised plan

**Revised Timeline**:
- Week 0: Planning & validation (1-2 days)
- Week 1: Database + Compliance backend (5 days)
- Week 2: Real-time infrastructure (5 days)
- Week 3: Frontend (5 days)
- Week 4: Integration testing & bug fixes (5 days)
- **Total: 4 weeks + 2 days**

**Confidence Level**: 85% (up from 70% with original plan)

**Green Light Criteria**:
- [ ] TRM Labs pricing confirmed < $1000/mo OR fallback identified
- [ ] Audit logs rollback plan documented
- [ ] Staging environment ready
- [ ] Team reviewed and agrees with 4-week timeline

---

**Next Step**: Review this critique, make adjustments, then proceed to implementation.
